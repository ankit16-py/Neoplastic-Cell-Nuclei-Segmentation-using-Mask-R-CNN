{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn import utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a bigger display\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize']= (7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path variables\n",
    "model_path= \"neoexp_logs/neoplast20210228T1521/mask_rcnn_neoplast_0049.h5\"\n",
    "test_img_path= \"datset/val_img_paths.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading configurations\n",
    "img_path= \"datset/images\"\n",
    "mask_path= \"datset/masks\"\n",
    "CLASS_NAMES = {1:\"NeoPlast\"}\n",
    "CLASS_COLORS={1:(1.0,0.0,0.0)}\n",
    "COCO_PATH = \"mask_rcnn_coco.h5\"\n",
    "LOGS_AND_MODEL_DIR = \"neoexp_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_split= 0.8\n",
    "exp_split= 1.0\n",
    "random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list= sorted(list(paths.list_images(img_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_img_num= int(len(img_path_list)*exp_split)\n",
    "exp_ids= [random.randint(0, len(img_path_list)-1) for i in range(exp_img_num)]\n",
    "exp_img_pathlist= np.array(img_path_list)[exp_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx= list(range(0, len(exp_img_pathlist)))\n",
    "random.shuffle(idx)\n",
    "num_train= int((len(exp_img_pathlist)-500)* data_split)\n",
    "trainIdxs= idx[:num_train]\n",
    "valIdxs= idx[num_train:len(idx)-500]\n",
    "testIdxs= idx[len(idx)-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sub-class and inherit the primary configuration class\n",
    "class NeoPlastConfig(Config):\n",
    "    # give the configuration a name\n",
    "    NAME = \"NeoPlast\"\n",
    "\n",
    "    # set the number of GPUs to use training along with the number of\n",
    "    # images per GPU which acts as the batch size\n",
    "    # set other hyperparameters in config file\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    LEARNING_RATE= 0.001\n",
    "    RPN_NMS_THRESHOLD= 0.8\n",
    "    WEIGHT_DECAY= 0.0001\n",
    "    USE_MINI_MASK= False\n",
    "\n",
    "    # set the number of steps per training epoch and validation cycle\n",
    "    STEPS_PER_EPOCH = len(trainIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
    "    VALIDATION_STEPS = len(valIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
    "\n",
    "    # number of classes (+1 for the background)\n",
    "    NUM_CLASSES = len(CLASS_NAMES) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class inherited from the initial config file\n",
    "# and stores inference configurations\n",
    "class NeoPlastInferenceConfig(NeoPlastConfig):\n",
    "    # set the number of GPUs and images per GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # set the minimum detection confidence (used to prune out false\n",
    "    # positive detections)\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary data loader class\n",
    "class NeoPlastDataset(utils.Dataset):\n",
    "    def __init__(self, imagePaths, classNames, width=256):\n",
    "        # call the parent constructor\n",
    "        super().__init__(self)\n",
    "\n",
    "        # store the image paths and class names along with the width details\n",
    "        # for further image processing\n",
    "        self.imagePaths = imagePaths\n",
    "        self.classNames = classNames\n",
    "        self.width = width\n",
    "\n",
    "    def load_cells(self, idxs):\n",
    "        # loop over all class names and add each to the dataset\n",
    "        for (classID, label) in self.classNames.items():\n",
    "            self.add_class(\"NeoPlast\", classID, label)\n",
    "\n",
    "        # loop over the image path indices\n",
    "        for i in idxs:\n",
    "            # extract the image filename to serve as the unique ID\n",
    "            imagePath = self.imagePaths[i]\n",
    "            filename = imagePath.split(os.path.sep)[-1]\n",
    "            # add the image to the dataset\n",
    "            self.add_image(\"NeoPlast\", image_id=filename,\n",
    "                path=imagePath)\n",
    "\n",
    "    def load_image(self, imageID):\n",
    "        # grab the image path, load it, and convert it from BGR to\n",
    "        # RGB color channel ordering because of OpenCV\n",
    "        p = self.image_info[imageID][\"path\"]\n",
    "        image = cv2.imread(p)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # resize the image, preserving the aspect ratio\n",
    "        image = imutils.resize(image, width=self.width)\n",
    "\n",
    "        # return the image\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, imageID):\n",
    "        # from image filename extract mask filename and path\n",
    "        filename= self.image_info[imageID][\"id\"].split(\".\")[0]\n",
    "        filenum= filename.split(\"_\")[1]\n",
    "        annotPath= os.path.sep.join([mask_path, \"mask_\"+filenum+\".png\"])\n",
    "        \n",
    "        # load mask and resize to width using nearest-neighbour interpolation\n",
    "        annotMask = cv2.imread(annotPath)\n",
    "        annotMask = cv2.split(annotMask)[0]\n",
    "        annotMask = imutils.resize(annotMask, width=self.width,\n",
    "                                   inter=cv2.INTER_NEAREST)\n",
    "\n",
    "        # determine the number of unique classes (instances) which is only 2\n",
    "        classIDs = np.unique(annotMask)\n",
    "\n",
    "        # remove background class\n",
    "        classIDs = np.delete(classIDs, [0])\n",
    "\n",
    "        # create a final mask container to store all the instances of image\n",
    "        masks = np.zeros((annotMask.shape[0], annotMask.shape[1], int(len(classIDs))),\n",
    "                         dtype=\"uint8\")\n",
    "\n",
    "        # loop over the class IDs\n",
    "        for (i, classID) in enumerate(classIDs):\n",
    "            # construct a mask for only the current instance\n",
    "            classMask = np.zeros(annotMask.shape, dtype=\"uint8\")\n",
    "            classMask[annotMask == classID] = 1\n",
    "\n",
    "            # store the class mask in the masks container\n",
    "            masks[:, :, i] = classMask\n",
    "\n",
    "        # return the mask array and class IDs as respective data-types\n",
    "        return (masks.astype(\"bool\"), np.ones((masks.shape[-1],), dtype=\"int32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = NeoPlastDataset(exp_img_pathlist, CLASS_NAMES)\n",
    "testDataset.load_cells(testIdxs)\n",
    "testDataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 49\n"
     ]
    }
   ],
   "source": [
    "inference_config = NeoPlastInferenceConfig()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=LOGS_AND_MODEL_DIR)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection over Union metric explanation\n",
    "It is the measure of the ratio between the intersection and the union of the predicted bounding-box and the ground-truth bounding-box for a detected object in an image, by the model.\n",
    "<br>\n",
    "<img src=\"ref_images/iou_equation.png\" width=\"500px\">\n",
    "<br>\n",
    "So depending upon this score, a bounding-box prediction can be classified as either bad or good as shown below\n",
    "<br>\n",
    "<img src=\"ref_images/IOU_classes.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision metric explanation\n",
    "<br>\n",
    "This metric is computed in 3 steps\n",
    "\n",
    "- Compute the precision, which is number of correctly predicted objects\n",
    "- Compute the recall, which measures how good of a job we did finding all the objects\n",
    "- Average together the maximum precision value across all recall levels in steps of size s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images= 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.752067281211984\n",
      "\n",
      "Operated on 400 images in 558.712s\n"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "start_time= time.time()\n",
    "image_ids = np.random.choice(testDataset.image_ids, num_images)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(testDataset, inference_config,\n",
    "                               image_id)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: {}\\n\".format(np.mean(APs)))\n",
    "print(\"Operated on {} images in {:.3f}s\".format(num_images, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panoptic Quality metrics\n",
    "<br>\n",
    "It is similar to mAP but also includes IoU in the actual metric calculation. It is a combination of IoU and Fn-Score generated from the model and hence measures the model's precison+recall performance and also the quality of segmentation done by the model.\n",
    "<br>\n",
    "<img src='ref_images/pan_metrics.png' width='500px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_label(pred, by_size=False):\n",
    "    pred_id = list(np.unique(pred))\n",
    "    pred_id.remove(0)\n",
    "    if len(pred_id) == 0:\n",
    "        return pred # no label\n",
    "    if by_size:\n",
    "        pred_size = []\n",
    "        for inst_id in pred_id:\n",
    "            size = (pred == inst_id).sum()\n",
    "            pred_size.append(size)\n",
    "        # sort the id by size in descending order\n",
    "        pair_list = zip(pred_id, pred_size)\n",
    "        pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n",
    "        pred_id, pred_size = zip(*pair_list)\n",
    "\n",
    "    new_pred = np.zeros(pred.shape, np.int32)\n",
    "    for idx, inst_id in enumerate(pred_id):\n",
    "        new_pred[pred == inst_id] = idx + 1    \n",
    "    return new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fast_pq(true, pred, match_iou=0.5):\n",
    "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
    "    \n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [None,]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "    \n",
    "    pred_masks = [None,]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_iou = np.zeros([len(true_id_list) -1, \n",
    "                             len(pred_id_list) -1], dtype=np.float64)\n",
    "\n",
    "    # caching pairwise iou\n",
    "    for true_id in true_id_list[1:]: # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0: # ignore\n",
    "                continue # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            iou = inter / (total - inter)\n",
    "            pairwise_iou[true_id-1, pred_id-1] = iou\n",
    "    #\n",
    "    if match_iou >= 0.5:\n",
    "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
    "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
    "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "        paired_true += 1 # index is instance id - 1\n",
    "        paired_pred += 1 # hence return back to original\n",
    "    else:  # * Exhaustive maximal unique pairing\n",
    "        #### Munkres pairing with scipy library\n",
    "        # the algorithm return (row indices, matched column indices)\n",
    "        # if there is multiple same cost in a row, index of first occurence \n",
    "        # is return, thus the unique pairing is ensure\n",
    "        # inverse pair to get high IoU as minimum   \n",
    "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "        ### extract the paired cost and remove invalid pair \n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "\n",
    "        # now select those above threshold level\n",
    "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
    "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
    "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
    "        paired_iou = paired_iou[paired_iou > match_iou]\n",
    "\n",
    "    # get the actual FP and FN\n",
    "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
    "\n",
    "    #\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
    "\n",
    "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datset/val_img_paths.txt\", \"r\") as f:\n",
    "    arr= f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "with open(\"datset/val_img_types.txt\", \"r\") as f:\n",
    "    arr_types= f.readlines()\n",
    "    f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chosen_img= 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_type_list= [i.splitlines()[0] for i in arr_types]\n",
    "img_type_list= img_type_list[:num_chosen_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_types = [\n",
    "                'gland',\n",
    "                'Bile-duct',\n",
    "                'Bladder',\n",
    "                'Breast',\n",
    "                'Cervix',\n",
    "                'Colon',\n",
    "                'Esophagus',\n",
    "                'HeadNeck',\n",
    "                'Kidney',\n",
    "                'Liver',\n",
    "                'Lung',\n",
    "                'Ovarian',\n",
    "                'Pancreatic',\n",
    "                'Prostate',\n",
    "                'Skin',\n",
    "                'Stomach',\n",
    "                'Testis',\n",
    "                'Thyroid',\n",
    "                'Uterus'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Panoptic Quality-> 0.6708943908513941\n",
      "\n",
      "Panoptic Quality per Tissue Type:-\n",
      "\n",
      "gland PQ: 0.7282411973028374 \n",
      "Bile-duct PQ: 0.6732049788341709 \n",
      "Bladder PQ: 0.7943104529246043 \n",
      "Breast PQ: 0.6682740679074229 \n",
      "Cervix PQ: 0.6574118006836814 \n",
      "Colon PQ: 0.5697431448381328 \n",
      "Esophagus PQ: 0.7280822814734743 \n",
      "HeadNeck PQ: 0.632452340651145 \n",
      "Kidney PQ: 0.6469073520634757 \n",
      "Liver PQ: 0.7257249424863959 \n",
      "Lung PQ: 0.605158889030525 \n",
      "Ovarian PQ: 0.7436484045044601 \n",
      "Pancreatic PQ: 0.5914464468713281 \n",
      "Prostate PQ: 0.7470174022050943 \n",
      "Skin PQ: 0.6955592990718643 \n",
      "Stomach PQ: 0.7751847258972315 \n",
      "Testis PQ: 0.6626548017565101 \n",
      "Thyroid PQ: 0.6497397746335498 \n",
      "Uterus PQ: 0.6156768926627144 \n"
     ]
    }
   ],
   "source": [
    "bPQ=[]\n",
    "\n",
    "for i in range(num_chosen_img):\n",
    "    image = cv2.imread(arr[i].splitlines()[0])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = imutils.resize(image, width=256)\n",
    "    mask_inf_path= \"datset/masks\\\\mask_\"+arr[i].splitlines()[0].split('\\\\')[-1].split('_')[-1]\n",
    "    r = model.detect([image], verbose=0)[0]\n",
    "    img_mask= cv2.imread(mask_inf_path)[:,:,0]\n",
    "    remaped_gt= remap_label(img_mask)\n",
    "    temp_mask= np.zeros((256, 256), dtype='int32')\n",
    "    count=1\n",
    "    for i in range(r['masks'].shape[2]):\n",
    "        tmp_mask= r['masks'][:,:,i]\n",
    "        tmp_mask_c= 1- tmp_mask\n",
    "        temp_mask*=tmp_mask_c\n",
    "        temp_mask+=count*tmp_mask\n",
    "        count+=1\n",
    "    [_, _, pq_bin], _ = get_fast_pq(remaped_gt, temp_mask)\n",
    "    bPQ.append([pq_bin])\n",
    "\n",
    "bPQ_final = np.nanmean([pq_bin[0] for pq_bin in bPQ])\n",
    "print(\"Binary Panoptic Quality-> {}\\n\".format(bPQ_final))\n",
    "print(\"Panoptic Quality per Tissue Type:-\\n\")\n",
    "\n",
    "for tissue_name in tissue_types:\n",
    "    indices = [i for i, x in enumerate(img_type_list) if x == tissue_name]\n",
    "    tissue_PQ = [bPQ[i] for i in indices]\n",
    "    print('{} PQ: {} '.format(tissue_name, np.nanmean(tissue_PQ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
